{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import division\n",
    "import random\n",
    "from keras.callbacks import History \n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, Lambda\n",
    "from keras.layers import MaxPooling2D, Dropout, BatchNormalization\n",
    "#from keras.utils import print_summary\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import pickle\n",
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import load_model\n",
    "import keras.utils\n",
    "\n",
    "#For Visualizations\n",
    "from scipy.stats import norm, skew\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(img):\n",
    "    resized_image = cv2.resize((cv2.cvtColor(img, cv2.COLOR_RGB2HSV))[:, :, 1], (40, 40))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_training(delta):\n",
    "    logs = []\n",
    "    features = []\n",
    "    labels = []\n",
    "    with open(labels_file, 'rt') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for line in reader:\n",
    "            logs.append(line)\n",
    "        log_labels = logs.pop(0)\n",
    "\n",
    "    for i in range(len(logs)):\n",
    "        for j in range(3):\n",
    "            img_path = logs[i][j]\n",
    "            img_path = features_directory + 'IMG' + (img_path.split('IMG')[1]).strip()\n",
    "            img = plt.imread(img_path)\n",
    "            features.append(image_preprocessing(img))\n",
    "            if j == 0:\n",
    "                labels.append(float(logs[i][3]))\n",
    "            elif j == 1:\n",
    "                labels.append(float(logs[i][3]) + delta)\n",
    "            else:\n",
    "                labels.append(float(logs[i][3]) - delta)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape\n",
    "\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 127.5 - 1., input_shape=(40, 40, 1)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='valid'))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='valid'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='valid'))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='valid'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=0.0001), loss=\"mse\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFromPickle():\n",
    "    with open(\"features\", \"rb\") as f:\n",
    "        features = np.array(pickle.load(f))\n",
    "    with open(\"labels\", \"rb\") as f:\n",
    "        labels = np.array(pickle.load(f))\n",
    "    return features, labels\n",
    "\n",
    "def augmentData(features, labels):\n",
    "    features = np.append(features, features[:, :, ::-1], axis=0)\n",
    "    labels = np.append(labels, -labels, axis=0)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "features, labels = loadFromPickle()\n",
    "features, labels = shuffle(features, labels)\n",
    "\n",
    "#do a Train Test Split\n",
    "train_x, val_x, train_y, val_y = train_test_split(features, labels, random_state=42, test_size=0.20)\n",
    "\n",
    "train_x = train_x.reshape(train_x.shape[0], 40, 40, 1)\n",
    "val_x = val_x.reshape(val_x.shape[0], 40, 40, 1)\n",
    "\n",
    "model = keras_model()\n",
    "filepath = \"./SelfDriving.h5\"\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath, verbose=1,monitor='val_loss', save_best_only=True)\n",
    "hist = History()\n",
    "callbacks_list = [es,checkpoint,hist]\n",
    "    \n",
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=10, batch_size=32,callbacks=callbacks_list)\n",
    "\n",
    "print_summary(model)\n",
    "\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fibered",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
